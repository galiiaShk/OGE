{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de3270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006eceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a8db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user numpy==1.24.3 --upgrade #probably with some limitation because of --user space installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn==1.0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7c9d9-e773-4b39-a19a-8e1d119eeaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import asyncio\n",
    "import pygame\n",
    "\n",
    "from google.protobuf.json_format import MessageToDict \n",
    "\n",
    "from numpy import linalg\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7023494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to use data.pickle and pretrained model.p of this project\n",
    "# Then you have to prepare your images (photos) with one (chord-)hand for training\n",
    "# Use function in next-to-last cell to create pickle data from your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then use the function in last cell to train RandomForestClassifier on your pickle data\n",
    "# It will create model.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "def play_chord(chord_name):\n",
    "\n",
    "    if not pygame.mixer.get_busy():\n",
    "        chord_map= {\n",
    "            'Minor1': ['AMoll_7c', 'AisMoll_7c', 'HMoll_7c', 'CMoll_7c', 'CisMoll_7c', 'DMoll_7c'],\n",
    "            'Minor2': ['AMoll_7c', 'CisMoll_7c', 'DMoll_7c', 'DisMoll_7c'],\n",
    "            'Minor3': ['FMoll_7c', 'FisMoll_7c', 'GMoll_7c', 'GisMoll_7c'],\n",
    "            'MajorToMinor': ['EMoll_7c'],\n",
    "            'Major2Minor': ['EMoll_7c'],\n",
    "            'FullBarre': ['Fullbarre_CDur_7c', 'Fullbarre_DDur_7c', 'Fullbarre_EDur_7c', 'Fullbarre_FDur_7c', 'Fullbarre_GDur_7c', 'Fullbarre_ADur_7c', 'Fullbarre_HDur_7c'],\n",
    "            'Barre': ['CisDur_7c', 'DisDur_7c', 'EDur_7c', 'FisDur_7c', 'GDur_7c', 'GisDur_7c', 'AisDur_7c', 'HDur_7c'],\n",
    "        }\n",
    "        \n",
    "        if chord_name not in chord_map:\n",
    "            print(f'Chord {chord_name} not found.')\n",
    "            return\n",
    "        \n",
    "        possible_chords = chord_map[chord_name]\n",
    "        selected_chord = random.choice(possible_chords)\n",
    "        filename = './chords/'+str(selected_chord)+'.wav'\n",
    "        pygame.mixer.Sound(filename).play()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_chord('Barre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44883aa5-cdb4-4fda-95db-b80130ae9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_finger_stretched(point1, point2, point3):\n",
    "    outcome = 0\n",
    "         #\n",
    "    distance1 = np.linalg.norm((point2 - point1), ord=2)\n",
    "    distance2 = np.linalg.norm((point3 - point1), ord=2)\n",
    "    if distance2 > distance1:\n",
    "        outcome = 1\n",
    "    \n",
    "    #check the result\n",
    "    #print(outcome, '\\n')\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ca378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_gesture(result):\n",
    "    if (result[0] == 1) and (result[1] == 0) and (result[2] == 0) and (result[3] == 0) and (result[4] == 0):\n",
    "        gesture = \"good\"\n",
    "    elif (result[0] == 1) and (result[1] == 1)and (result[2] == 0) and (result[3] == 0) and (result[4] == 0):\n",
    "        gesture = \"Travis picking\"\n",
    "    elif (result[0] == 0) and (result[1] == 1)and (result[2] == 0) and (result[3] == 0) and (result[4] == 0):\n",
    "        gesture = \"one\"\n",
    "    elif (result[0] == 0) and (result[1] == 0)and (result[2] == 1) and (result[3] == 0) and (result[4] == 0):\n",
    "        gesture = \"VERY BAD\"\n",
    "    elif (result[0] == 0) and (result[1] == 1)and (result[2] == 1) and (result[3] == 0) and (result[4] == 0):\n",
    "        gesture = \"two\"\n",
    "    elif (result[0] == 1) and (result[1] == 1)and (result[2] == 1) and (result[3] == 0) and (result[4] == 0):\n",
    "        gesture = \"3 finger picking\"\n",
    "    elif (result[0] == 0) and (result[1] == 1)and (result[2] == 1) and (result[3] == 1) and (result[4] == 0):\n",
    "        gesture = \"three\"\n",
    "    elif (result[0] == 0) and (result[1] == 1)and (result[2] == 1) and (result[3] == 1) and (result[4] == 1):\n",
    "        gesture = \"four\"\n",
    "    elif (result[0] == 1) and (result[1] == 1)and (result[2] == 1) and (result[3] == 1) and (result[4] == 1):\n",
    "        gesture = \"five\"\n",
    "    elif (result[0] == 1) and (result[1] == 0)and (result[2] == 0) and (result[3] == 0) and (result[4] == 1):\n",
    "        gesture = \"Shaka\"\n",
    "    elif (result[0] == 0) and (result[1] == 0)and (result[2] == 1) and (result[3] == 1) and (result[4] == 1):\n",
    "        gesture = \"OK or plectrum\"\n",
    "    elif(result[0] == 0) and (result[1] == 0) and (result[2] == 0) and (result[3] == 0) and (result[4] == 0):\n",
    "        gesture = \"closed\"\n",
    "    else:\n",
    "        gesture = \"unknown/not detected\"\n",
    "    \n",
    "    return gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25884c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    model_dict = pickle.load(open('./model.p', 'rb'))\n",
    "    model = model_dict['model']\n",
    "    \n",
    "    labels_dict = {0: 'Minor1', 1: 'Minor2', 2: 'Minor3', 3: 'MajorToMinor', 4: 'Major2Minor', 5: 'FullBarre', 6: 'Barre'}\n",
    "    \n",
    "    width = 1280\n",
    "    height = 720\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Delete following settings and replace resize function for more FPS\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH,width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT,height)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    hands = mp.solutions.hands.Hands(static_image_mode=False,\n",
    "                             max_num_hands=2,\n",
    "                             min_tracking_confidence=0.5,\n",
    "                             min_detection_confidence=0.5)\n",
    "    \n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    \n",
    "    previousTime = 0\n",
    "    currentTime = 0\n",
    "    \n",
    "    ready = False\n",
    "    \n",
    "    # Array for 5 fingers as figure\n",
    "    figure = [0 for element in range(5)]\n",
    "    \n",
    "    # Array for 0-20 trackpoints and 2 hands\n",
    "    landmark = np.empty((21, 2))\n",
    "    \n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        \n",
    "        #Horizontally flip the image to get right hand for the right and left for the left hand\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = cv2.resize(frame,(width,height))\n",
    "        \n",
    "        #Convert image from webcam back to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Should improve performance, but no difference to see\n",
    "        #frame_rgb.flags.writeable = False\n",
    "        \n",
    "        results = hands.process(frame_rgb)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            #frame_rgb.flags.writeable = True\n",
    "            for handsnumber, lms in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(frame, lms, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                for i in results.multi_handedness:\n",
    "                    \n",
    "                    # writes the information like index, score and label of hand\n",
    "                    label = MessageToDict(i)[\n",
    "                        'classification'][0]['label']\n",
    "                    \n",
    "                    \n",
    "                    if label == 'Left':\n",
    "                        \n",
    "                        # If left hand is recognized it will  \n",
    "                        data_aux = []\n",
    "                        x_ = []\n",
    "                        y_ = []\n",
    "    \n",
    "                        H, W, _ = frame.shape\n",
    "    \n",
    "                        for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        \n",
    "                        # alternative CODE in COMMENT is not finished yet\n",
    "                        #for idx, classification in enumerate(results.multi_handedness):\n",
    "                        #    if classification.classification[0].index == 0:\n",
    "                                \n",
    "                                mp_drawing.draw_landmarks(\n",
    "                                    frame,  # image to draw\n",
    "                                    hand_landmarks,  # model output\n",
    "                                    mp_hands.HAND_CONNECTIONS,  # hand connections\n",
    "                                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "    \n",
    "                                for i in range(len(hand_landmarks.landmark)):\n",
    "                                    x = hand_landmarks.landmark[i].x\n",
    "                                    y = hand_landmarks.landmark[i].y\n",
    "                                    x_.append(x)\n",
    "                                    y_.append(y)\n",
    "    \n",
    "                                for i in range(len(hand_landmarks.landmark)):\n",
    "                                    x = hand_landmarks.landmark[i].x\n",
    "                                    y = hand_landmarks.landmark[i].y\n",
    "                                    data_aux.append(x - min(x_))\n",
    "                                    data_aux.append(y - min(y_))\n",
    "    \n",
    "                                x1 = int(min(x_) * W) - 10\n",
    "                                y1 = int(min(y_) * H) - 10\n",
    "    \n",
    "                                x2 = int(max(x_) * W) - 10\n",
    "                                y2 = int(max(y_) * H) - 10\n",
    "    \n",
    "                                if (len(data_aux) == 42):\n",
    "                                    prediction = model.predict([np.asarray(data_aux)])\n",
    "                                    predicted_character = labels_dict[int(prediction[0])]\n",
    "    \n",
    "                                    if ready:\n",
    "                                        play_chord(predicted_character)\n",
    "    \n",
    "                                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "                                    cv2.putText(frame, predicted_character, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                                                    cv2.LINE_AA)\n",
    "                     \n",
    "                        \n",
    "                    if label == 'Right':\n",
    "                \n",
    "                        #for id, lm in enumerate(lms.landmark):\n",
    "                        if len(results.multi_hand_landmarks) > 1:\n",
    "                            for id, lm in enumerate(results.multi_hand_landmarks[1].landmark): #ONLY FOR ONE HAND WITHOUT SECOND for LOOP\n",
    "    \n",
    "                                h, w, _ = frame.shape\n",
    "                                cx = int(lm.x * w) \n",
    "                                cy = int(lm.y * h)\n",
    "                                cv2.circle(frame, (cx, cy), 3, (128, 128, 128))\n",
    "    \n",
    "                                landmark_ = [cx, cy]\n",
    "                                landmark[id,:] = landmark_\n",
    "                                #print(id)\n",
    "                                #print(lm)\n",
    "    \n",
    "                            #Marks the top of fingers with different colors and thickness\n",
    "                                if id == 4:\n",
    "                                    cv2.circle(frame, (cx, cy), 6, (0, 0, 0), cv2.FILLED)\n",
    "                                if id == 8:\n",
    "                                    cv2.circle(frame, (cx, cy), 12, (255, 0, 0), cv2.FILLED)\n",
    "                                if id == 12:\n",
    "                                    cv2.circle(frame, (cx, cy), 12, (0, 255, 0), cv2.FILLED)\n",
    "                                if id == 16:\n",
    "                                    cv2.circle(frame, (cx, cy), 12, (0, 0, 255), cv2.FILLED)\n",
    "                                if id == 20:\n",
    "                                    cv2.circle(frame, (cx, cy), 12, (255, 0, 255), cv2.FILLED)\n",
    "    \n",
    "                            for i in range(5):\n",
    "                                if i == 0:\n",
    "                                    #pinky\n",
    "                                    figure_ = are_finger_stretched(landmark[17],landmark[4*i+2],landmark[4*i+4])\n",
    "                                else:\n",
    "                                    #wrest\n",
    "                                    figure_ = are_finger_stretched(landmark[0],landmark[4*i+2],landmark[4*i+4])\n",
    "    \n",
    "                                figure[i] = figure_\n",
    "                            #print(figure, '\\n')\n",
    "    \n",
    "                            gesture_solution = detect_gesture(figure)\n",
    "                            if gesture_solution == \"OK or plectrum\":\n",
    "                                ready = True\n",
    "                            if gesture_solution == \"Shaka\":\n",
    "                                ready = False\n",
    "                            cv2.putText(frame, f\"{gesture_solution}\", (240, 18*(handsnumber)), cv2.FONT_HERSHEY_PLAIN, 2, (128, 255, 128), 5)\n",
    "              \n",
    "        #Shows Frames per Second\n",
    "            currentTime = time.time()\n",
    "            fps = 1/(currentTime-previousTime)\n",
    "            previousTime = currentTime        \n",
    "            cv2.putText(frame, str(int(fps)), (10, 35), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3) #Pos,Font,Scale,Color,Thick\n",
    "                \n",
    "            cv2.imshow(\"Hand Tracking\", frame) #Name of Window and the Live-Image\n",
    "            \n",
    "        if cv2.waitKey(1) == ord('q') : \n",
    "            #quit with Q\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4554cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#For finger angle calculation - not finished yet\n",
    "#\n",
    "\"\"\"\n",
    "def draw_finger_angles(frame, results, joint_list):\n",
    "    \n",
    "    # Loop through hands\n",
    "    for hand in results.multi_hand_landmarks:\n",
    "        #Loop through joint sets \n",
    "        for joint in joint_list:\n",
    "            a = np.array([lm.landmark[joint[0]].x, lm.landmark[joint[0]].y]) # First coord\n",
    "            b = np.array([lm.landmark[joint[1]].x, lm.landmark[joint[1]].y]) # Second coord\n",
    "            c = np.array([lm.landmark[joint[2]].x, lm.landmark[joint[2]].y]) # Third coord\n",
    "            \n",
    "            radians = np.arctan2(c[1] - b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "            angle = np.abs(radians*180.0/np.pi)\n",
    "            \n",
    "            if angle > 180.0:\n",
    "                angle = 360-angle\n",
    "                \n",
    "            cv2.putText(frame, str(round(angle, 2)), tuple(np.multiply(b, [640, 480]).astype(int)),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return frame\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "class Joint:\n",
    "    def __init__(self, name,XValue, YValue):\n",
    "     self.name = name\n",
    "     self.XValue = XValue\n",
    "     self.YValue = YValue\n",
    "\n",
    "    def get_name(self):\n",
    "     return self.name\n",
    "    \n",
    "class Finger:\n",
    "    def __init__(self, name, joints):\n",
    "        self.name = name\n",
    "        self.joints = []  # Initialize joints as an empty list\n",
    "        self.set_joints(joints)  # Call set_joints method to set the joints\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    def get_joints(self):\n",
    "        # Check if any joint is None\n",
    "        for joint in self.joints:\n",
    "            if joint is None:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def set_joints(self, joints):\n",
    "        self.joints.extend(joints)\n",
    "\n",
    "     \n",
    "class Handie:\n",
    "    def __init__(self, frame, fingers):\n",
    "        self.frame = frame\n",
    "        self.fingers = fingers\n",
    "\n",
    "    def get_frame(self):\n",
    "        return self.frame\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "DATA_DIR = '/Users/pc/Desktop/Gestenerkennung/ComputerVisionEngineerYoutube/Gestenerkennung/Datensatz_Kamera/Dur'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "frames = []\n",
    "handies = []\n",
    "\n",
    "\n",
    "Thumb = None\n",
    "Index =  None\n",
    "Middle =  None\n",
    "Ring =  None\n",
    "Pinky =  None\n",
    "\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    if dir_ == \".DS_Store\":\n",
    "        print(\"Skipping unwanted file in {dir_} directory: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    if dir_ == \".thumbs.db\" or dir_ == \"desktop.ini\" :\n",
    "        print(\"Skipping unwanted file in {dir_} directory: {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    string_length = len(dir_)   \n",
    "    substringdir_ = dir_[1: string_length] \n",
    "\n",
    "    full_dir_path = os.path.join(DATA_DIR,dir_)\n",
    "\n",
    "   \n",
    "\n",
    "    frame_count = 0\n",
    "    framecounter=0\n",
    "    jointcounter=0\n",
    "    if full_dir_path == \"/Users/pc/Desktop/Gestenerkennung/ComputerVisionEngineerYoutube/Gestenerkennung/Datensatz_Kamera/Dur/EDur_7c.mp4\":\n",
    "     \n",
    "    \n",
    "\n",
    "\n",
    "     cap=cv2.VideoCapture(full_dir_path)\n",
    "     if(cap.isOpened()==False):\n",
    "        print(\"couldnt open File\")\n",
    "        break\n",
    "     while(cap.isOpened()):\n",
    "      ret, frame = cap.read() \n",
    "      if ret == True: \n",
    "    # Display the resulting frame \n",
    "       if frame_count%2==0:\n",
    "      \n",
    "        frames.append(frame_count)\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(img_rgb)\n",
    "        temporaljoints=[]\n",
    "        if results.multi_hand_landmarks:\n",
    "          for hand_landmarks in results.multi_hand_landmarks:\n",
    "             for i in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "           \n",
    "                \n",
    "                if i>=1 and i<=4:\n",
    "                  yoint=Joint(\"thumbjoint\",x,y)\n",
    "                  temporaljoints.append(yoint)\n",
    "                #create Thumbbone\n",
    "                if  i==4:\n",
    "                  Thumb=Finger(\"thumb\", temporaljoints) \n",
    "                  temporaljoints=[] \n",
    "                if i>4 and i<=8:\n",
    "                  yoint=Joint(\"indexjoint\",x,y)\n",
    "                  temporaljoints.append(yoint)\n",
    "                #createindexbone\n",
    "                if i==8:\n",
    "                    Index=Finger(\"index\", temporaljoints)\n",
    "                    temporaljoints=[]\n",
    "                if i>8 and i<=12:\n",
    "                  yoint=Joint(\"middlejoint\",x,y)\n",
    "                  temporaljoints.append(yoint)\n",
    "                #createmiddlebone  \n",
    "                if i==12:\n",
    "                    Middle=Finger(\"middle\", temporaljoints)\n",
    "                    temporaljoints=[]   \n",
    "                if i>12 and i<=16:\n",
    "                  joint=Joint(\"ringjoint\",x,y)\n",
    "                  temporaljoints.append(yoint)\n",
    "                #createringbone  \n",
    "                if i==12:\n",
    "                    Ring=Finger(\"ring\", temporaljoints)\n",
    "                    temporaljoints=[]   \n",
    "                if i>16 and i<=20:\n",
    "                  joint=Joint(\"pinkyjoint\",x,y)\n",
    "                  temporaljoints.append(yoint)\n",
    "                  \n",
    "                  if i==20:\n",
    "                   Pinky=Finger(\"pinky\", temporaljoints)\n",
    "                   \n",
    "                   temporaljoints=[]   \n",
    "                if(framecounter !=frame_count and i==jointcounter):\n",
    "                 jointcounter+=4\n",
    "                 connectedjoints=[]\n",
    "                 connectedjoints.append(Thumb)\n",
    "                 connectedjoints.append(Index)\n",
    "                 connectedjoints.append(Middle)\n",
    "                 connectedjoints.append(Ring)\n",
    "                 connectedjoints.append(Pinky)\n",
    "                 print(connectedjoints[0].name)\n",
    "                 currentHand=Handie(framecounter,connectedjoints)\n",
    "                 handies.append(currentHand)\n",
    "                 framecounter=frame_count\n",
    "                 currentHand=None\n",
    "                    \n",
    "        cv2.imshow('Image', frame)\n",
    "       \n",
    "\n",
    "       frame_count+=1\n",
    "       delay = int(1000 / cap.get(cv2.CAP_PROP_FPS))  # Calculate delay based on video frame rate\n",
    "       key = cv2.waitKey(delay)\n",
    "  \n",
    "       #count total number of frames and then close instances\n",
    "       if frame_count ==int(cap.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        print(frame_count)\n",
    "        break\n",
    "    \n",
    "cap.release() \n",
    "\n",
    "\n",
    "def extractbonedata(allhanddata, fingernumber,jointnumber):\n",
    "   framex=[]\n",
    "   framey=[]\n",
    "   colors=[]\n",
    "   greyscaleint=0\n",
    "   for handie in allhanddata:\n",
    "     greyscaleint+=100\n",
    "     colors.append(greyscaleint)\n",
    "     framex.append(handie.fingers[fingernumber].joints[jointnumber].XValue)\n",
    "     framey.append(handie.fingers[fingernumber].joints[jointnumber].YValue)\n",
    "     \n",
    "   return framex,framey,colors\n",
    "\n",
    "\n",
    "def calculateScatterplott(XValues, YValues, colors):\n",
    "  Xmax_value = max(XValues)\n",
    "  Xmin_value = min(XValues)\n",
    "\n",
    "  ymax_value = max(YValues)\n",
    "  ymin_value = min(YValues)\n",
    "\n",
    "  plt.gcf().set_facecolor('lightblue')\n",
    "\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(1, 1, 1) # nrows, ncols, index\n",
    "\n",
    "  ax.set_facecolor('xkcd:lightblue')\n",
    "  ax.set_facecolor((0.2, 0.47, 0.42))\n",
    "  plt.scatter(XValues, YValues, c=colors, cmap='gray')\n",
    "  Xstd_dev = statistics.stdev(XValues)\n",
    "  Ystd_dev = statistics.stdev(YValues)\n",
    "  # Add labels and title\n",
    "  plt.xlabel('X Values')\n",
    "  plt.ylabel('Y Values')\n",
    "  plt.title('Std_x:' +str(Xstd_dev)+\" Std_y:\"+str(Ystd_dev))\n",
    "\n",
    "\n",
    "  plt.xlim(Xmin_value-0.01, Xmax_value+0.01)\n",
    "  plt.ylim(ymin_value-0.01,ymax_value+0.01)\n",
    "\n",
    "# Show plot\n",
    "  plt.colorbar(label='Time')  # Add color bar to indicate intensity values\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "print(\"value beingextracted\")\n",
    "counthands=0\n",
    "for x in range(4):\n",
    "  for y in range(3):\n",
    "   values=extractbonedata(handies,x,y)\n",
    "   calculateScatterplott(values[0],values[1],values[2])\n",
    "   counthands+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4767705-59f9-45eb-ab57-5492d78ac301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is only necessary to prepare your images (photos) for training\n",
    "# Currently all images will be read from folder \"data\" and subfolders of it will act as labels\n",
    "# please use numbers for subfolder names\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "DATA_DIR = './data'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        data_aux = []\n",
    "\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "\n",
    "#Save data            \n",
    "f = open('data.pickle', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b113ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is only necessary to TRAIN RandomForestClassifier on your pickle data\n",
    "\n",
    "data_dict = pickle.load(open('./data.pickle', 'rb'))\n",
    "\n",
    "# You can print it out to check if the data structure is homogeneous\n",
    "### print(data_dict.keys())\n",
    "### print(data_dict)\n",
    "\n",
    "#Data and Labels are lists, so they have to be converted here\n",
    "Data_type = object\n",
    "\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "#Dataset is split here in 80% training and 20% test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "#Simple but very fast modeltype to train - good for older hardware/training on cpu\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "score = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print('{}% of samples are classified correctly '.format(score * 100))\n",
    "\n",
    "#save model\n",
    "f = open('model.p', 'wb')\n",
    "pickle.dump({'model': model}, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
