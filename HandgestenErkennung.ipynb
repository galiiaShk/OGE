{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import keyboard \n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#init\n",
    "#---------------------\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "hands= mp.solutions.hands.Hands(static_image_mode=False,\n",
    "                        max_num_hands=1,\n",
    "                        min_tracking_confidence=0.5,\n",
    "                        min_detection_confidence=0.5)\n",
    "\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "#------------------------------\n",
    "#variables \n",
    "savedGesturesFilePath=\"HandGestures.txt\"\n",
    "#basic quit function to close all windows\n",
    "def quit(): \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        cap.release() \n",
    "        cv2.destroyAllWindows()\n",
    "        return True    \n",
    "#---------------------------------------\n",
    "# reads the handcoordinates on the \"r\"-Key\n",
    "def readCoords(init):\n",
    "    if keyboard.is_pressed('r')|init:\n",
    "        f = open(savedGesturesFilePath,\"r\")\n",
    "        result= f.read()\n",
    "        f.close()\n",
    "        res = json.loads(result)\n",
    "        return res\n",
    "#---------------------------------------\n",
    "#writes  the handcoordinates on the \"space\"-Key\n",
    "def writeCoords():\n",
    "     if keyboard.is_pressed('w'): \n",
    "        f = open(savedGesturesFilePath,\"w\")\n",
    "        f.write(str(recognizedPoints)) \n",
    "        f.close()      \n",
    "#---------------------------------------     \n",
    "\n",
    "#---------------------------------------   \n",
    "# draw the standard hand from mediapipe\n",
    "def drawHandMediaPipe(img, lm):\n",
    "    h, w, _ = img.shape\n",
    "    cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "    cv2.circle(img, (cx, cy), 3, (255, 0, 255)) \n",
    "    mpDraw.draw_landmarks(img, result.multi_hand_landmarks[0], mp.solutions.hands.HAND_CONNECTIONS)\n",
    "#---------------------------------------   \n",
    "#Draws the saved gesture, the one from media pipe and compares both,\n",
    "# TODO: THis function should be split in two for a single recognition part\n",
    "def drawSavedHandGesture(id,h,w, recognizedColor):\n",
    "     \n",
    "     if len(savedCoords[0])<=2:\n",
    "            return\n",
    "     else:\n",
    "     # get the hand wrist as compare offset x,y,z and merge them to the xyz\n",
    "        pivotPointX = result.multi_hand_landmarks[0].landmark[1].x-savedCoords[0][0]\n",
    "        pivotPointY = result.multi_hand_landmarks[0].landmark[1].y -savedCoords[0][1]\n",
    "        pivotPointZ = result.multi_hand_landmarks[0].landmark[1].z -savedCoords[0][2]\n",
    "        pivotXYZ = pivotPointX,pivotPointY,pivotPointZ\n",
    "        #Draw the tracked handgesture as before but without the lines in between\n",
    "        pivotTracked = int( result.multi_hand_landmarks[0].landmark[id].x*w), int( result.multi_hand_landmarks[0].landmark[id].y*h)\n",
    "        # calculate the savedCoordinates with the offset of the current projected gesture to match the hand wrist position independed of the screen\n",
    "        savedOffset =  [savedCoords[id][0]+pivotXYZ[0],  savedCoords[id][1]+pivotXYZ[1],  savedCoords[id][2]+pivotXYZ[2]]\n",
    "        #for visual representation, it has to be redrawn in respect to the width and height ratio of the screen\n",
    "        pivotOffsetImageRatio = [int ((savedCoords[id][0]+pivotXYZ[0])*w), int ((savedCoords[id][1]+pivotXYZ[1])*h), savedCoords[id][2]+pivotXYZ[2]]\n",
    "        pivotOffsetImageRatioXY = int ((savedCoords[id][0]+pivotXYZ[0])*w), int ((savedCoords[id][1]+pivotXYZ[1])*h)\n",
    "        diffXy=abs((np.subtract(pivotTracked,pivotOffsetImageRatioXY)))\n",
    "        #Compare gestures\n",
    "        if(diffXy[0]<50 and diffXy[1]<50):\n",
    "            recognizedColor =(0,255,0)\n",
    "        #draw the circle for the tracked hand\n",
    "        cv2.circle(img, (pivotTracked), 5, (255, 0, 0)) \n",
    "        #draw the circle for the saved matching hand gesture\n",
    "        cv2.circle(img ,pivotOffsetImageRatioXY,5, recognizedColor)\n",
    "     \n",
    "        return pivotOffsetImageRatio\n",
    "#Init params\n",
    "recognizedPoints = np.array([0,0,0])\n",
    "savedOffsetPoints= np.array([0,0,0])\n",
    "savedCoords = readCoords(True)\n",
    "recognizedColor = (0,0,255)\n",
    "\n",
    "while True:    \n",
    "    _,img = cap.read()\n",
    "    result= hands.process(img)\n",
    "   # if the gestrues should be compared this frame, start the compare method in the for loop\n",
    "    if result.multi_hand_landmarks:\n",
    "        recognizedPoints = []# clear the array before the loop starts to avoid overflow    \n",
    "        savedOffsetPoints = []# clear the array before the loop starts to avoid overflow  \n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        # for each recognized point on the hand, get the id and the bone coordinates\n",
    "        for id, lm in enumerate(result.multi_hand_landmarks[0].landmark):   \n",
    "            #calculate the saved handgesture in respect to the current hand position to make it independed of the image aspect\n",
    "            savedOffsetPoints.append(drawSavedHandGesture(id,h,w, recognizedColor))\n",
    "            #set the default points of the current handpostion\n",
    "            recognizedPoints.append([lm.x*w, lm.y*h, lm.z])# append the circles from the hand to the array, 21 in total        \n",
    "       \n",
    "        # default hand drawing from puling\n",
    "        #drawHandMediaPipe(img, lm)\n",
    "        # Draw the result\n",
    "    cv2.imshow(\"Hand tracking test\", img)\n",
    "\n",
    "    if quit():\n",
    "        break\n",
    "\n",
    "    writeCoords()\n",
    "    readCoords(False)  \n",
    "  \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
